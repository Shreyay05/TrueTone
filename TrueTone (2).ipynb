{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12120,"status":"ok","timestamp":1750671697073,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"siNKmMsp0l75","outputId":"5c3b826f-13f2-4faf-ab97-e33b29601167"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44288,"status":"ok","timestamp":1750671742890,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"utwKr0um69Dh","outputId":"dfb8358a-1314-49d9-8aab-dac481d38551"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Unzipped to /content/img_align_celeba/\n"]}],"source":["import zipfile\n","\n","zip_path = \"/content/drive/MyDrive/image_align_celeba.zip\"  # ⬅️ change path here\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/img_align_celeba\")\n","\n","print(\"✅ Unzipped to /content/img_align_celeba/\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11393,"status":"ok","timestamp":1750671801716,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"duXaWA-V7jPz"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1792,"status":"ok","timestamp":1750671807595,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"e7aPr3qL7qIX"},"outputs":[],"source":["# Load CSVs\n","skin_df = pd.read_csv(\"/content/drive/MyDrive/celeba_labeled_skin_full.csv\")\n","shade_df = pd.read_csv(\"/content/drive/MyDrive/foundation_shade_mapping_expanded.csv\")\n","\n","# Merge to get recommended shades\n","merged_df = pd.merge(skin_df, shade_df, on=[\"SkinTone\", \"Undertone\"], how=\"left\")\n","merged_df.dropna(subset=[\"RecommendedShades\"], inplace=True)\n","\n","# Label Encoding\n","skin_enc = LabelEncoder()\n","under_enc = LabelEncoder()\n","shade_enc = LabelEncoder()\n","\n","merged_df[\"SkinToneClass\"] = skin_enc.fit_transform(merged_df[\"SkinTone\"])\n","merged_df[\"UndertoneClass\"] = under_enc.fit_transform(merged_df[\"Undertone\"])\n","merged_df[\"ShadeClass\"] = shade_enc.fit_transform(merged_df[\"RecommendedShades\"])\n","\n","# Split\n","train_df, val_df = train_test_split(merged_df, test_size=0.1, random_state=42)\n","\n","# Image directory\n","image_dir = \"/content/img_align_celeba/img_align_celeba/img_align_celeba\"\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1750671809925,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"qW5PJr9673km"},"outputs":[],"source":["class CelebaShadeDataset(Dataset):\n","    def __init__(self, dataframe, image_dir, transform=None):\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        img_path = os.path.join(self.image_dir, row[\"Image\"])\n","        image = Image.open(img_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        skin_label = row[\"SkinToneClass\"]\n","        under_label = row[\"UndertoneClass\"]\n","        shade_label = row[\"ShadeClass\"]\n","        return image, skin_label, under_label, shade_label\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1750671812589,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"T5WIKQVe771j"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*3, [0.5]*3)\n","])\n","\n","train_dataset = CelebaShadeDataset(train_df, image_dir, transform)\n","val_dataset = CelebaShadeDataset(val_df, image_dir, transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1750671814850,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"paXY4hEf8EUx"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","class ShadePredictorCNN(nn.Module):\n","    def __init__(self, num_skin, num_under, num_shade):\n","        super(ShadePredictorCNN, self).__init__()\n","\n","        resnet = models.resnet18(pretrained=True)\n","        self.base = nn.Sequential(*list(resnet.children())[:-1])  # remove the FC layer\n","\n","        self.head_skin = nn.Linear(512, num_skin)\n","        self.head_under = nn.Linear(512, num_under)\n","        self.head_shade = nn.Linear(512, num_shade)\n","\n","    def forward(self, x):\n","        x = self.base(x)              # output shape: (batch_size, 512, 1, 1)\n","        x = torch.flatten(x, 1)       # shape: (batch_size, 512)\n","\n","        out_skin = self.head_skin(x)\n","        out_under = self.head_under(x)\n","        out_shade = self.head_shade(x)\n","\n","        return out_skin, out_under, out_shade\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1004,"status":"ok","timestamp":1750671818086,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"sRpcMcQm8F1o","outputId":"e2633b37-b4c6-4ad1-eee6-26ede04e3530"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 81.3MB/s]\n"]}],"source":["model = ShadePredictorCNN(\n","    num_skin=len(skin_enc.classes_),\n","    num_under=len(under_enc.classes_),\n","    num_shade=len(shade_enc.classes_)\n",")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1750671820880,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"B4TPHwDp8KbV"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion_skin = nn.CrossEntropyLoss()\n","criterion_under = nn.CrossEntropyLoss()\n","criterion_shade = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zI5H0Jc88SrW","outputId":"c8d24755-64ca-4a1b-ebc2-fecf4c8c0557"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:34<00:00,  4.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 | Loss: 3726.8934 | Skin Acc: 0.8165 | Undertone Acc: 0.9071 | Shade Acc: 0.7436\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:25<00:00,  4.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10 | Loss: 2849.1826 | Skin Acc: 0.8574 | Undertone Acc: 0.9316 | Shade Acc: 0.8001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:19<00:00,  4.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10 | Loss: 2535.0161 | Skin Acc: 0.8742 | Undertone Acc: 0.9402 | Shade Acc: 0.8230\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:18<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10 | Loss: 2225.1684 | Skin Acc: 0.8886 | Undertone Acc: 0.9490 | Shade Acc: 0.8448\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:19<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10 | Loss: 1910.2173 | Skin Acc: 0.9060 | Undertone Acc: 0.9574 | Shade Acc: 0.8683\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:18<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10 | Loss: 1550.2789 | Skin Acc: 0.9244 | Undertone Acc: 0.9659 | Shade Acc: 0.8933\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2839/2839 [10:18<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10 | Loss: 1245.6701 | Skin Acc: 0.9404 | Undertone Acc: 0.9736 | Shade Acc: 0.9167\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 722/2839 [02:38<07:24,  4.76it/s]"]}],"source":["epochs = 10\n","\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    correct_skin = correct_under = correct_shade = 0\n","\n","    for images, skin_labels, under_labels, shade_labels in tqdm(train_loader):\n","        images = images.to(device)\n","        skin_labels = skin_labels.to(device)\n","        under_labels = under_labels.to(device)\n","        shade_labels = shade_labels.to(device)\n","\n","        out_skin, out_under, out_shade = model(images)\n","\n","        loss_skin = criterion_skin(out_skin, skin_labels)\n","        loss_under = criterion_under(out_under, under_labels)\n","        loss_shade = criterion_shade(out_shade, shade_labels)\n","        loss = loss_skin + loss_under + loss_shade\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        correct_skin += (out_skin.argmax(1) == skin_labels).sum().item()\n","        correct_under += (out_under.argmax(1) == under_labels).sum().item()\n","        correct_shade += (out_shade.argmax(1) == shade_labels).sum().item()\n","\n","    total = len(train_dataset)\n","    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f} | \"\n","          f\"Skin Acc: {correct_skin/total:.4f} | \"\n","          f\"Undertone Acc: {correct_under/total:.4f} | \"\n","          f\"Shade Acc: {correct_shade/total:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56692,"status":"ok","timestamp":1748696183977,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"DOzDw8i6aP9L","outputId":"43ddeecb-d220-4d8a-a19e-67855c5a7b5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Final Accuracy | Skin Tone: 0.8688 | Undertone: 0.9311 | Foundation Shade: 0.8109\n"]}],"source":["model.eval()\n","correct_skin = correct_under = correct_shade = total = 0\n","\n","with torch.no_grad():\n","    for x, y_skin, y_under, y_shade in val_loader:\n","        x, y_skin, y_under, y_shade = x.to(device), y_skin.to(device), y_under.to(device), y_shade.to(device)\n","        out_skin, out_under, out_shade = model(x)\n","\n","        pred_skin = torch.argmax(out_skin, dim=1)\n","        pred_under = torch.argmax(out_under, dim=1)\n","        pred_shade = torch.argmax(out_shade, dim=1)\n","\n","        correct_skin += (pred_skin == y_skin).sum().item()\n","        correct_under += (pred_under == y_under).sum().item()\n","        correct_shade += (pred_shade == y_shade).sum().item()\n","        total += y_skin.size(0)\n","\n","print(f\"✅ Final Accuracy | Skin Tone: {correct_skin/total:.4f} | Undertone: {correct_under/total:.4f} | Foundation Shade: {correct_shade/total:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117,"status":"ok","timestamp":1748696336470,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"nZkWAP9pay9m","outputId":"4c6d3ffc-ec16-4839-c74f-4f5002dfaf2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model and encoders saved.\n"]}],"source":["import joblib\n","\n","# Save the model state\n","torch.save(model.state_dict(), \"shade_predictor_model.pth\")\n","\n","# Save the label encoders\n","joblib.dump(skin_enc, \"skin_encoder.pkl\")\n","joblib.dump(under_enc, \"under_encoder.pkl\")\n","joblib.dump(shade_enc, \"shade_encoder.pkl\")\n","\n","print(\"✅ Model and encoders saved.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1748696348684,"user":{"displayName":"Shreya Pradhan","userId":"01315164029270260566"},"user_tz":-180},"id":"vC5wi4pRbKTK","outputId":"f4a2cdce-3669-4b23-dbb8-a327f7b9725b"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model and encoders loaded.\n"]}],"source":["import joblib\n","from torchvision import models\n","\n","# Load encoders\n","skin_enc = joblib.load(\"skin_encoder.pkl\")\n","under_enc = joblib.load(\"under_encoder.pkl\")\n","shade_enc = joblib.load(\"shade_encoder.pkl\")\n","\n","# Re-initialize the model with correct output sizes\n","model = ShadePredictorCNN(\n","    num_skin=len(skin_enc.classes_),\n","    num_under=len(under_enc.classes_),\n","    num_shade=len(shade_enc.classes_)\n",")\n","\n","# Load trained weights\n","model.load_state_dict(torch.load(\"shade_predictor_model.pth\", map_location=device))\n","model.to(device)\n","model.eval()\n","\n","print(\"✅ Model and encoders loaded.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1RgZQa4bOKl"},"outputs":[],"source":["from torchvision import transforms\n","from PIL import Image\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],  # ResNet ImageNet mean\n","        std=[0.229, 0.224, 0.225]    # ResNet ImageNet std\n","    )\n","])\n","\n","def preprocess_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    return transform(image).unsqueeze(0).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7_G_RF4bRAu"},"outputs":[],"source":["def predict_image(image_path):\n","    img_tensor = preprocess_image(image_path)\n","\n","    with torch.no_grad():\n","        out_skin, out_under, out_shade = model(img_tensor)\n","\n","    # Get predicted class indices\n","    skin_idx = torch.argmax(out_skin, dim=1).item()\n","    under_idx = torch.argmax(out_under, dim=1).item()\n","    shade_idx = torch.argmax(out_shade, dim=1).item()\n","\n","    # Decode class labels\n","    skin_label = skin_enc.inverse_transform([skin_idx])[0]\n","    under_label = under_enc.inverse_transform([under_idx])[0]\n","    shade_label = shade_enc.inverse_transform([shade_idx])[0]\n","\n","    return {\n","        \"Skin Tone\": skin_label,\n","        \"Undertone\": under_label,\n","        \"Shade\": shade_label\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tuMacLKkbT4I"},"outputs":[],"source":["from google.colab import files\n","import torch\n","import joblib\n","\n","uploaded = files.upload()  # Upload image\n","image_path = list(uploaded.keys())[0]\n","\n","# Define the device to use (GPU if available, otherwise CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load encoders\n","skin_enc = joblib.load(\"skin_encoder.pkl\")\n","under_enc = joblib.load(\"under_encoder.pkl\")\n","shade_enc = joblib.load(\"shade_encoder.pkl\")\n","\n","# Re-initialize the model with correct output sizes\n","# Assuming ShadePredictorCNN class is defined in the notebook\n","model = ShadePredictorCNN(\n","    num_skin=len(skin_enc.classes_),\n","    num_under=len(under_enc.classes_),\n","    num_shade=len(shade_enc.classes_)\n",")\n","\n","# Load trained weights\n","model.load_state_dict(torch.load(\"shade_predictor_model.pth\", map_location=device))\n","model.to(device)\n","model.eval()\n","\n","result = predict_image(image_path)\n","print(\"🎯 Prediction:\")\n","for k, v in result.items():\n","    print(f\"{k}: {v}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1i2WJj2m1qzQ8UjnYoiTOXguZhbSQTMRX","authorship_tag":"ABX9TyNIdYrBhir9yhD9fpWJcrA5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}